{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare ETD Light Curves for analysis in AIJ #\n",
    "\n",
    "This code has been written hastily in order to prepare the light curves downloaded from [Exoplanet Transit Database (ETD)](http://var2.astro.cz/ETD/) to be analyzed in [AstroImageJ (AIJ)](https://www.astro.louisville.edu/software/astroimagej/) by converting the column that keeps time to BJD-TDB format, computing the AIRMASS based on the location of the observers and the coordinates of the object and printing an output file that will be used in the analysis with AIJ.\n",
    "\n",
    "Since ETD light curves have been acquired by amateur observers, they ignore airmass-detrending, which improves the precision of mid-transit times measured from those light curves. So I have written a small code-piece in Python (hosted in this Jupyter notebook) to convert the light curves in ETD to BJD-TDB time scale, compute the airmass, which you can find below.\n",
    "\n",
    "You can either run each cell one by one (by pressing `Ctrl+Enter` at the same time or from the Kernel menu, by clicking the option `Restart & Run All` once for all. The cells with code in it have `In` prefix (short for Input), there are also cells for formatted text (like this one, called markdown cells) to explain how the code works and provide directions for what to do next. For more information on [Jupyter notebooks](https://jupyter.org/), you can have a look at the tutorial from the [Data Camp](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook) or use the Notebook Help and Use Interface Tour options in the `Help` menu. I strongly suggest using Keyboard Shortcuts which are listed from the Help menu as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the needed packages\n",
    "from astropy import time, coordinates as coord, units as u\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display, FileLink\n",
    "from ipywidgets import FileUpload\n",
    "import ipython_blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and upload the light curve data ###\n",
    "\n",
    "Most observers in ETD upload their light curve in a well-defined format. Nevertheless it is not trivial to determine which separator they use and how they name their columns. Most importantly, they can add information on the parameters of the photometry (aperture sizes, number of stars etc.) to first, second or sometimes the last line of their files. Some observers skip column header names and just dump the light curve data to their light curve files. Although these inconvenience can be properly handled and avoided in the code, unfortunately, I don't have time to fix these issues. So I kindly ask you to prepare your light curve file before you upload it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: palevioletred; color: white; padding: 10px;\">\n",
    "Please open the light curve file in your local copy and delete all the unnecessary lines, that are the lines without column headers or data, whereever they appear and save them. If there is no line for the column header at the beginning of your files, please add one with column names relevant to the and delimit them with the same separator the observer use to delimit his/her data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: yellow; color: black; padding: 10px;\">\n",
    "Now please click on the upload button below the next cell and upload your light curve file that you want to be converted for analysis in AIJ.\n",
    "</div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aec8176fd8b4a2894fb501ef88d9a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.dat, .txt, .text', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let the user upload the data first\n",
    "upload = FileUpload(accept='.dat, .txt, .text', \n",
    "    multiple=False)  # We want to convert once at a time\n",
    "display(upload)\n",
    "%block upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_file = upload.value\n",
    "filename = list(uploaded_file.keys())[0]\n",
    "with open(\"./lc.txt\", \"wb\") as fp:\n",
    "    fp.write(uploaded_file[filename][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the light curve file ###\n",
    "\n",
    "The code then reads the file. However ETD observers, unfortunately, separate the columns in their data files using different delimiters such as `space`, `<TAB>`, `,` etc. So we need to know the delimiter and ask the user to enter it. You can see the content of your file from this [link](./lc.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to know the separator used in the file to \n",
    "separator = input(\"Please enter the delimiter used to separate the columns in your file. Enter 't' if your file is tab delimited, 's' if space delimited without single quotes: \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if separator == 't':\n",
    "    separator = '\\t'\n",
    "elif separator == 's':\n",
    "    separator = ' '\n",
    "lc = pd.read_csv(\"lc.txt\", sep=separator, skipinitialspace=True)\n",
    "print(\"Your light curve is: \")\n",
    "print(lc.head())\n",
    "# Now that we are done with the original light curve file\n",
    "# We can delete it from the server\n",
    "os.remove(\"lc.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column names with important information ###\n",
    "\n",
    "We need to know which column keeps the time information, which one keeps the flux (or magnitude) and which one keeps its error. These are the only required columns. So provide (exactly) the name of each column when asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask which column is which\n",
    "jdcol = input(\"Which column keeps your time in JD?\\n\")\n",
    "flux = input(\"Which column keeps your flux (or magnitude)?\\n\")\n",
    "fluxerr = input(\"Which column keeps your flux (or magnitude) errors? If it is not in your file then hit <enter>\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the light curve ###\n",
    "\n",
    "If everything went well, when you run the cell below your light curve should display. If your light curve is upside down, this means that the brightness is in magnitude units. You don't have to do anything but only tick the relevant box (`Input in mag`) in AIJ (y-axis menu) to indicate that your light curve is in magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the light curve\n",
    "# and remind the user if the light curve is upside down\n",
    "# that it is in magnitudes\n",
    "%matplotlib inline\n",
    "plt.plot(lc[jdcol],lc[flux],'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time format and scale ###\n",
    "\n",
    "For every time frame, there is a format (YYYY-MM-DD, 245xxxx.xxxxx, etc.) and a scale (UTC, TAI, TDB, etc.). The default scale in ETD is UTC. So we only the reference time frame. Whether it is JD (geocentric), HJD (heliocentric) or BJD (barycentric). We then use this information to convert the times to barycentric dynamic scale (TDB) in BJDs (BJD-TDB). This information is either given in the header of your light curve file (the first line) or in the window when you click TRESCA link in ETD, just below the transit profiles where the mid-transit times and their errors are listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which reference frames are your timings in (JD, HJD or BJD) in UTC\n",
    "jdtype = input(\"What is the reference frame for the timings reported in UTC scale Please enter 'JD' for geocentric, 'HJD' for heliocentric, 'BJD' for barycentric values?: \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Removal ###\n",
    "\n",
    "For the moment there is a very simple outlier removal code piece below, which will be changed with an algorithm based on standard deviations of moving medians in the future. But you can always remove the outliers in the AIJ too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "# Discarding criteria is 5*sigma\n",
    "mu = lc[flux].mean()\n",
    "sigma = lc[flux].std()\n",
    "llim = mu - 5*sigma\n",
    "ulim = mu + 5*sigma\n",
    "# index of the points out of the limits\n",
    "index2drop = lc[(lc[flux] > ulim) | (lc[flux] < llim)].index\n",
    "lc.drop(index2drop , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No error column! ###\n",
    "\n",
    "There will be data files without a column filled with errors on the brightness values. If no such column exists, then the code computes the standard deviation of flux (or mag) for the first and last 5 data points and assigns the number to all data points as their error bars. This is only for convenience, EXOFAST weighs all data points the same since the errors are the same and the mid-transit time error is calculated from the goodness of fit statistics of the model. So the magnitude of that error bar has no effect when it is the same for all data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if error column is empty, calculate standard deviation of\n",
    "# first 5 and last 5 points and use it for all as a fudge factor\n",
    "# exofast already weighs these equally\n",
    "if fluxerr == '':\n",
    "    series4std = pd.concat([lc[flux][:5],lc[flux][-6:]])\n",
    "    fluxstd = series4std.std()\n",
    "    fluxerr = flux + '_err'\n",
    "    lc[fluxerr] = fluxstd*np.ones(len(lc[flux]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates of the host star: ###\n",
    "\n",
    "If your object is not found in the Simbad, and the code is not able to bring its coordinates (highly unlikely), then it asks for your help. Then please enter the RA and DEC of your star (in J2000 epoch from Simbad database) in the required format (hh mm ss.s for RA and dd mm ss.s, you can copy the entire line for this information in J2000 epoch in the Simbad query result and paste here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to find the star's coordinates in Simbad\n",
    "# Get the name of the light curve file from the user\n",
    "hoststar = input(\"Please enter the name of the host star as is given in Simbad: \\n\")\n",
    "try:\n",
    "    star_coords = coord.SkyCoord.from_name(hoststar)\n",
    "except:\n",
    "    RA = input(\"Please enter the right ascension of your star in hh mm ss.s format: \\n\")\n",
    "    DEC = input(\"Please enter the declination of your star in dd mm ss.s format: \\n\")\n",
    "    star_coords = coord.SkyCoord(RA, DEC, frame='icrs',\\\n",
    "                        unit=(u.hourangle,u.deg), equinox=\"J2000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of the Observer ###\n",
    "\n",
    "For BJD-TDB and AIRMASS calculation, the code needs to know where the observation has been made. You can provide this information either by entering the name of the database (unfortunately most amateur observatories reporting their data to ETD are not in the list) or entering the address of the observatory, which you can copy from the window opens when you click on the TRESCA link (it then looks for the address in Google Earth) or simply by providing the geographical latitude and longitude in degrees. This information is also provided in the TRESCA link below the name of the observatory. The precision (only integers) is sufficient for our purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now let us determine the location of the observer\n",
    "print(\"The observatories in our database are \\n\")\n",
    "print(\"Please be patient, this may take some time...\\n\")\n",
    "print(coord.EarthLocation.get_site_names())\n",
    "observatory = input(\"Please enter the name of the observatory. If your observatory is not in the list hit <enter>\\n\")\n",
    "if observatory == '':\n",
    "    observatory_address = input(\"Try entering the address of the observatory look for its coordinates in Google Earth: \\n\")\n",
    "    if observatory_address == '':\n",
    "        obslong = float(input(\"Please enter the longitude of the observatory in d.ddd format (east is positive): \\n\"))\n",
    "        obslat = float(input(\"Please enter the latitude of the observatory in dd.dddd format (north is positive): \\n\"))\n",
    "        obsalt = float(input(\"Please enter the altitude of the observatory in meters (if not known enter 0): \\n\"))\n",
    "        obsloc = coord.EarthLocation(lat=obslat*u.deg, lon=obslong*u.deg, height=obsalt*u.m)\n",
    "    else: \n",
    "        try:\n",
    "            obsloc = coord.EarthLocation.of_site(observatory_address)\n",
    "        except:\n",
    "            print(\"The address you have entered can not be found in Google Earth!\")\n",
    "            obslong = float(input(\"Please enter the longitude of the observatory in d.ddd format (east is positive): \\n\"))\n",
    "            obslat = float(input(\"Please enter the latitude of the observatory in dd.dddd format (north is positive): \\n\"))\n",
    "            obsalt = float(input(\"Please enter the altitude of the observatory in meters (if not known enter 0): \\n\"))\n",
    "            obsloc = coord.EarthLocation(lat=obslat*u.deg, lon=obslong*u.deg, height=obsalt*u.m)\n",
    "else:\n",
    "    obsloc = coord.EarthLocation.of_site(observatory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to BJD-TDB ###\n",
    "\n",
    "Then the code converts the timings to BJD-TDB by adding the time it takes for the light to travel from the Earth (geocentric JD case) to the barycenter or from the center of the Sun to the barycenter (heliocentric HJD case). If the timings are reported in BJD, onl the scale is converted to TDB from the UTC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: yellow; color: black; padding: 10px;\">\n",
    "    <b> WARNINIG: </b> If you get an error for not being able to connect to the USNO server, please try to run this cell by simultaneously hitting <u>`Ctrl + Enter`</u>. This can be caused by a problem either in your connection or in USNO server. If you have to run this again, please run the code cells after this, one by one again <u>`Ctrl + Enter`</u> because they may have run with the incorrect barycentric time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the timings to BJD-TDB\n",
    "# make sure they are numeric\n",
    "lc[jdcol] = pd.to_numeric(lc[jdcol]).astype(float)\n",
    "lc[flux] = pd.to_numeric(lc[flux]).astype(float)\n",
    "lc[fluxerr] = pd.to_numeric(lc[fluxerr]).astype(float)\n",
    "times = time.Time(lc[jdcol], format='jd',scale='utc', location=obsloc)\n",
    "# Cacluate bbarycentric or heliocentric time difference\n",
    "# converts UTC to BJD and add ltt diffrence\n",
    "if jdtype == \"JD\":\n",
    "    ltt_bary = times.light_travel_time(star_coords)\n",
    "elif jdtype == 'HJD':\n",
    "    ltt_helio = times.light_travel_time(star_coords, 'heliocentric')\n",
    "    times -= ltt_helio\n",
    "    ltt_bary =  times.light_travel_time(star_coords)\n",
    "elif jdtype == 'BJD':\n",
    "    ltt_bary = 0.\n",
    "else:\n",
    "    print(\"Your timing frame is not recognized\")\n",
    "    os.exit()\n",
    "time_barycentre = times.tdb + ltt_bary\n",
    "bjd_tdb = time_barycentre.value\n",
    "times_bjd_tdb = time.Time(bjd_tdb, format='jd', scale='tdb')\n",
    "lc['BJD-TDB'] = times_bjd_tdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airmass Computation ###\n",
    "\n",
    "Then the airmass is computed from the altitude-azimuth coordinates of the object with the formula given by Hardie (1962), which is valid for all zenith angles smaller than 85 degress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the altitude / azimuth coordinates for the object \n",
    "altaz = star_coords.transform_to(coord.AltAz(obstime=times, location=obsloc))\n",
    "# and zenith angle\n",
    "secz = 1 / np.cos(altaz.zen)\n",
    "# to determine the airmass from Hardie (1962)\n",
    "X = secz - 0.0018167*(secz - 1) - 0.002875*(secz - 1)**2 - 0.0008083*(secz -1)**3\n",
    "lc['airmass'] = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the new light curve file ###\n",
    "\n",
    "Now the output file is written in four columns (BJD-TDB, flux or mag, its error, and airmass) to an output file with the same file root ending with the suffix <i>_converted.dat</i> in the relevant (for your host star) data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the data in pandas dataframe lc to a new file\n",
    "# First find the index of the last '.' character where the extension starts\n",
    "indext = len(filename) - filename[-1::-1].find('.') - 1\n",
    "file2wr = filename[:indext]+'_converted.dat'\n",
    "# Now we sort the lc in ascending order of BJD-\n",
    "lc = lc.sort_values(by=['BJD-TDB'])\n",
    "try:\n",
    "    lc.to_csv(file2wr, sep = '\\t', \\\n",
    "          float_format = '%.6f', \\\n",
    "          columns=['BJD-TDB', flux, fluxerr, 'airmass'],\\\n",
    "          index=True)\n",
    "    local_file = FileLink(file2wr, result_html_prefix=\"Click here to download: \")\n",
    "    display(local_file)\n",
    "    print(\"Your file is ready to download\")\n",
    "except:\n",
    "    print(\"\"\"There is an expected error in writing your file.\n",
    "Please make sure you have run all the code cells\n",
    "and they have not thrown error messages. Then\n",
    "please check if you have permission to write\n",
    "in the folder you try to save your file\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good luck! ###\n",
    "\n",
    "The code has no error-handling unfortunately. So <b><u>you are at your own risk</u></b>. You have to enter the information correctly. Otherwise it crashes! If an unexpected error occur please let us know and we will correct the code if the error is some bug or direct you otherwise.\n",
    "\n",
    "Once your file is ready, please open this file with AIJ. By your eye (or by computing if you know how to do it), try to find the ingress and egress points. Enter them in the main window upper right (Right and Left Limits) copy them to the boxes down below in the same window to normalization limits. And then in the y-axis menu (long menu) where you control what is plotted; please tick the box if the unit of the flux is magnitude in the input file. Then it is converted to flux by AIJ. Then in the same menu fit the sections of the light curve before the ingress and after the egress (green boxes on each side of a white box) and enter the name of the airmass column (airmass) to the trend drop-down menu to its right. And then normalize the light curve in the same way. Then you should click on the left most button next to the first row in this menu, which is a disc symbol to provide the flux_dn, and fluxer_dn (these are detrended and normalized flux values and their errors you produced but may have different names based on the names of the columns in the original data file). You don't have to add BJD_dn column because we have it already! \n",
    "\n",
    "Then from the main window, save the entire light curve with all the plot configurations as mostly you do from \"save with options\" option. When asks the columns for the datasubset file please enter BJD-TDB, flux, fluxerr, airmass, flux_dn, fluxerr_dn. And that's it. save all the output files somewhere.  \n",
    "\n",
    "Have fun exoplaneteers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
